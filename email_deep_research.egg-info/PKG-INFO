Metadata-Version: 2.4
Name: email-deep-research
Version: 0.1.0
Summary: Deep learning research for email search and processing
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: datasets>=3.4.1
Requires-Dist: diskcache>=5.6.3
Requires-Dist: huggingface-hub>=0.29.3
Requires-Dist: ipykernel>=6.29.5
Requires-Dist: kaggle>=1.5.12
Requires-Dist: langchain-core>=0.3.51
Requires-Dist: mail-parser>=3.15.0
Requires-Dist: matplotlib>=3.10.1
Requires-Dist: openpipe-art
Requires-Dist: pandas>=1.3.0
Requires-Dist: panza>=0.1.0
Requires-Dist: pip>=25.0.1
Requires-Dist: pytest>=8.3.5
Requires-Dist: python-dotenv>=1.1.0
Requires-Dist: tabulate>=0.9.0
Requires-Dist: tiktoken>=0.9.0
Requires-Dist: tqdm>=4.62.0
Requires-Dist: transformers>=4.50.3
Requires-Dist: skypilot[runpod]>=0.8.1
Requires-Dist: openpipe==4.49.0
Requires-Dist: litellm>=1.65.0.post1
Requires-Dist: ipywidgets>=8.1.6
Requires-Dist: polars
Dynamic: license-file

The goal of this project is to train a model, using RL, to efficiently search through a large dataset of emails to answer a user's query. The idea is that an agent so trained could be eg. exposed through a Gmail plugin, and let users ask natural-language queries such as "what time does my wife's flight arrive on Friday" or "what are the next steps I committed to for project X", and let the agent search the email to find relevant results.

## Data

The agent is both trained and validated on the Enron email dataset. To generate training data, we iterated over the email inboxes of several Enron employees. For each one, we fed their emails into a prompt and asked the LLM to come up with a list of plausible questions that the emails collectively answer. We then used these questions to train the agent.
